<%
__author__ = "Doug Wendel"
__copyright__ = "Copyright 2009-2010, Qiime Web Analysis"
__credits__ = ["Doug Wendel"]
__license__ = "GPL"
__version__ = "1.0.0.dev"
__maintainer__ = ["Doug Wendel"]
__email__ = "wendel@colorado.edu"
__status__ = "Development"
%>

<h3>Please wait while metadata values are written to the database...</h3>

<script type="text/javascript">
function updateStatus(currentItem, totalFieldCount, divPrefix)
{
    // Build our output
    var pcent = parseInt((currentItem / totalFieldCount) * 100);
    var message = "Writing " + currentItem + " of " + totalFieldCount + " items (" + pcent + "%)<br/>";
    
    // Write the message
    document.getElementById(divPrefix + "_container").style.visibility = "visible";
    document.getElementById(divPrefix + "_status").innerHTML = message;
    document.getElementById(divPrefix + "_progress").style.width = pcent + "%";
}
</script>


<%
# The obligatory data access import
from data_access_connections import data_access_factory
from enums import ServerConfig
from metadata_worker import *
import threading
import thread
import copy
from time import sleep

# Get our data_access instance
data_access = data_access_factory(ServerConfig.data_access_type)

# Grab a couple of session variables
study_name = sess['study_name']
study_id = sess['study_id']
portal_type = sess['portal_type']

if sess.has_key('load_type'):
    load_type = sess['load_type']
    del sess['load_type']
    sess.save()
else:
    load_type = 'update'

req.write('LOAD TYPE: %s' % load_type)

# Remove any existing metadata if a reload is required
if load_type == 'reload':
    data_access.deleteStudy(study_id, 0)
else:
    data_access.deleteStudy(study_id, 1)

# Variables to collect our data
sample_key_fields = {}
prep_key_fields = {}
host_key_fields = {}

key_field = None
with_errors = False

sample_fields = []
host_fields = []
prep_fields = []
all_other_fields = []
key_field_errors = []

timeseries_template = None

# Get references to our files
files = []
prep_template_present = False
for item in form:
    if 'study_template' in item:
        files.append(form[item])
    elif 'sample_template' in item:
        files.append(form[item])
    elif 'prep_template' in item:
        files.append(form[item])
        prep_template_present = True
    elif 'timeseries_template' in item:
        timeseries_template = form[item]

# If not EMP, make sure we have 2 files. If not we're screeeeewd.
if portal_type == 'emp':
    pass
elif len(files) != 2:
    req.write('Missing files! I could only find these:<br/>')
    for item in files:
        req.write(item + '<br/>')

# Clear and re-insert our study templates
data_access.clearStudyTemplates(study_id)
for filename in sess['templates']:
    data_access.addTemplateFile(study_id, filename)

# Read in the files and put into da bucket of values
validated_values = {}
for name in files:
    f = open(name, 'r')
    for line in f:
        vals = line.split('::')
        validated_values[str(vals[0]).strip()] = str(vals[1]).strip()
        
# Add any corrected values passed in the form...
for item in form:
    parts = item.split(':')
    
    # Not a metadata field if length of parts is wrong
    if len(parts) != 4:
        continue
    else:
        validated_values[item] = form[item]

# Make one pass to shuffle all fields into the right buckets
for item in validated_values:
    parts = item.split(':')
    
    # Not a metadata field if length of parts is wrong
    if len(parts) != 4:
        continue
    
    # Sort the parts into more meaningful variable names
    field_type = parts[0]
    row_num = parts[1]
    field_name = parts[3]
    field_value = validated_values[item]
    
    # Skip the project name field here since we don't want to
    # change the name the user typed when creating their study. This value
    # may show up in some legacy files or could be added by the user at a
    # later time. 
    if field_name.upper() == 'PROJECT_NAME':
        continue
    
    # Sample rows
    if  field_type == 'sample' and field_name == 'sample_name':
        if field_value == '' or field_value == None:
            req.write('<br/>ERROR: Key value is blank (%s)<br/>' % str(item))
            key_field_errors.append(item)
 
        sample_fields.append(item)
        sample_key_fields[row_num] = field_value
        
    # Host rows 
    elif field_type == 'sample' and field_name == 'host_subject_id':
        if field_value == '' or field_value == None:
            req.write('<br/>ERROR: Key value is blank (%s)<br/>' % str(item))
            key_field_errors.append(item)

        host_fields.append(item)
        host_key_fields[row_num] = field_value
    
    # Prep rows 
    elif field_type == 'prep' and field_name == 'sample_name':
        if field_value == '' or field_value == None:
            req.write('<br/>ERROR: Key value is blank (%s -- "%s" )<br/>' % (str(item), validated_values[item]))
            key_field_errors.append(item)        

        prep_fields.append(item)
        prep_key_fields[row_num] = field_value
    
    # All other fields will be inserted in step 3
    else:
        all_other_fields.append(item)

# de-indent
%>

<!-- Divs for sample -->
<div name="sample_container" id="sample_container" style="visibility:hidden;">
    <p style="font-size:12px; font-weight:bold;">Sample Key Values:</p>
    <div name="sample_status" id="sample_status" style="font-size:12px"></div>
    <div class="progress-container">
        <div style="width: 0%" name="sample_progress" id="sample_progress">
        </div>
    </div>
    <br/><br/>
</div>

<%
if prep_template_present:
    # Indent
%>

<!-- Divs for prep -->
<div name="prep_container" id="prep_container" style="visibility:hidden;">
    <p style="font-size:12px; font-weight:bold;">Prep Key Values:</p>
    <div name="prep_status" id="prep_status" style="font-size:12px"></div>
    <div class="progress-container">
        <div style="width: 0%" name="prep_progress" id="prep_progress">
        </div>
    </div>
    <br/><br/>
</div>

<%

if len(host_fields) > 0:
    # Indent
%>
    
<!-- Divs for host -->
<div name="host_container" id="host_container" style="visibility:hidden;">
    <p style="font-size:12px; font-weight:bold;">Host Key Values:</p>
    <div name="host_status" id="host_status" style="font-size:12px"></div>
    <div class="progress-container">
        <div style="width: 0%" name="host_progress" id="host_progress">
        </div>
    </div>
    <br/><br/>
</div>

<%

# end if
%>


<!-- Divs for the rest of the fields -->
<div name="the_rest_container" id="the_rest_container" style="visibility:hidden;">
    <p style="font-size:12px; font-weight:bold;">Metadata Values (this may take a while):</p>
    <div name="the_rest_status" id="the_rest_status" style="font-size:12px"></div>
    <div class="progress-container">
        <div style="width: 0%" name="the_rest_progress" id="the_rest_progress">
        </div>
    </div>
    <br/><br/>
</div>

<%

# Define the update interval size
update_intervals = 100

# Insert the sample key rows
item_count = len(sample_fields)
current_item = 0
batch_size = item_count / update_intervals
if batch_size == 0:
    batch_size = 1
for item in sample_fields:
    current_item += 1
    field_value = validated_values[item]
    data_access.createSampleKey(study_id, field_value)
    if current_item % batch_size == 0 or (item_count - current_item) < update_intervals:
        req.write('<script type="text/javascript">updateStatus(%s, %s, "sample");</script>' % (current_item, item_count))

# Insert the prep key rows now that sample rows all exist
item_count = len(prep_fields)
current_item = 0
batch_size = item_count / update_intervals
if batch_size == 0:
    batch_size = 1 
for item in prep_fields:
    current_item += 1
    field_value = validated_values[item]
    row_num = item.split(':')[1]
    data_access.createPrepKey(study_id, field_value, row_num)
    if current_item % batch_size == 0 or (item_count - current_item) < update_intervals:
        req.write('<script type="text/javascript">updateStatus(%s, %s, "prep");</script>' % (current_item, item_count))

# Insert the host key rows now that sample rows all exist
item_count = len(host_fields)
batch_size = item_count / update_intervals
if batch_size == 0:
    batch_size = 1
current_item = 0
if len(host_fields) > 0:
    # Add host_subject_id to study_actual_columns
    data_access.addStudyActualColumn(study_id, 'host_subject_id', '"HOST"');
    
    for item in host_fields:
        current_item += 1
        parts = item.split(':')
        row_num = parts[1]
        field_value = validated_values[item]
        sample_name = sample_key_fields[row_num]
        data_access.createHostKey(study_id, sample_name, field_value)
        if current_item % batch_size == 0 or (item_count - current_item) < update_intervals:
            req.write('<script type="text/javascript">updateStatus(%s, %s, "host");</script>' % (current_item, item_count))

# To hold the current bucket of metadata values
item_list = []
threads = []
thread_count = 1

# Sets the number of metadata fields to be processed by each thread
item_count = len(all_other_fields)
current_item = 0
bucket_size = item_count / thread_count

# Define the thread callback
def _updateCallback():
    global update_intervals
    global current_item
    global item_count
    
    batch_size = item_count / update_intervals
    if batch_size == 0:
        batch_size = 1
    current_item += 1
    if current_item % batch_size == 0 or (item_count - current_item) < 100:
        req.write('<script type="text/javascript">updateStatus(%s, %s, "the_rest");</script>' \
            % (current_item, item_count))
    
def _errorCallback(e):
    global with_errors
    
    with_errors = True
    req.write(str(e) + '<p/>')

lock = Lock()

# Go workers go!
data_access.fields.clear()
for item in all_other_fields:
    #req.write(str(item) + '....' + validated_values[item] + '<br/>')
    item_list.append(item)
    if len(item_list) == bucket_size:
        t = MetadataWorkerThread(validated_values, copy.deepcopy(item_list), sample_key_fields, \
            prep_key_fields, host_key_fields, study_name, study_id, data_access, _updateCallback,\
            _errorCallback, lock)
        threads.append(t)
        t.start()
        item_list = []
        
# If there are any items left, process those last
if len(item_list) > 0:
    t = MetadataWorkerThread(validated_values, item_list, sample_key_fields, prep_key_fields, \
        host_key_fields, study_name, study_id, data_access, _updateCallback, _errorCallback, lock)
    threads.append(t)
    t.start()

for t in threads:
    t.join()
    
# Load the timeseries file into a new table
if timeseries_template:
    data_access.saveTimeseriesData(study_id, timeseries_template, req)

if with_errors:
    req.write('<h3>Upload Completed With Errors</h3>')
    req.write('<p style="font-size:12px">You should review the errors above, make the appropriate adjustments to your metadata files, then re-submit them to your study.</p>')
    req.write('<a href="fusebox.psp?page=upload_metadata.psp">Upload corrected metadata</a>')
    
    # Update the database flag for the failed upload
    data_access.updateMetadataFlag(study_id, 'n')
else:
    if sess['is_admin'] == 1:
        req.write('<p/><h3>Thread count: %s</h3>' % thread_count)
        
    req.write('<p/><h3>Upload Completed!</h3>')
    req.write('<p style="font-size:8px">yahoo!</p>')
    req.write('<img src="img/firework3.gif"/>')
    
    # One more calc to perform - figure out the age in years for host studies
    data_access.calcAgeInYears(study_id)
    
    # Update the database flag for successful metadata upload
    data_access.updateMetadataFlag(study_id, 'y')

# end if/else
%>
